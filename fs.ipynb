{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import undetected_chromedriver as uc\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "# Set up undetected-chromedriver\n",
    "options = uc.ChromeOptions()\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "# Create the WebDriver instance\n",
    "driver = uc.Chrome(options=options)\n",
    "\n",
    "# Open Chrome and let the user log in manually\n",
    "print(\"Please log in to the site manually in the opened Chrome window. Press Enter when done...\")\n",
    "input(\"Press Enter to continue after logging in...\")\n",
    "\n",
    "# Load your DataFrame with URLs\n",
    "urls_df = pd.read_csv('test.csv')  # Replace 'HStoExcel.csv' with your actual CSV file\n",
    "\n",
    "# Initialize a list to store PIDs\n",
    "pids = []\n",
    "\n",
    "# Loop through URLs and capture information\n",
    "for index, row in urls_df.iterrows():\n",
    "    url = row['url']\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "    \n",
    "    # Find all buttons with data-testid=\"pid\" and extract their text\n",
    "    pid_elements = driver.find_elements(By.CSS_SELECTOR, 'button[data-testid=\"pid\"]')\n",
    "    for element in pid_elements:\n",
    "        pids.append(element.text)\n",
    "    \n",
    "    # Print or save the PIDs as needed\n",
    "    print(f\"Page {index + 1}: Found {len(pid_elements)} PIDs.\")\n",
    "\n",
    "# Optionally, save the PIDs to a CSV file\n",
    "pids_df = pd.DataFrame(pids, columns=['PID'])\n",
    "pids_df.to_csv('captured_pids.csv', index=False)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "# Optionally, save the captured data to a CSV file\n",
    "# captured_data_df.to_csv('captured_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import undetected_chromedriver as uc\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "\n",
    "# Set up undetected-chromedriver\n",
    "options = uc.ChromeOptions()\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "# Create the WebDriver instance\n",
    "driver = uc.Chrome(options=options)\n",
    "\n",
    "# Open Chrome and let the user log in manually\n",
    "print(\"Please log in to the site manually in the opened Chrome window. Press Enter when done...\")\n",
    "input(\"Press Enter to continue after logging in...\")\n",
    "\n",
    "# Load your DataFrame with URLs\n",
    "urls_df = pd.read_csv('test.csv')  # Replace 'test.csv' with your actual CSV file\n",
    "urls_df['Father'] = urls_df['Father'].astype(object)\n",
    "urls_df['Mother'] = urls_df['Mother'].astype(object)\n",
    "\n",
    "# Initialize a list to store PIDs or aria-labels\n",
    "pids = []\n",
    "\n",
    "# Loop through URLs and capture information\n",
    "for index, row in urls_df.iterrows():\n",
    "    url = row['url']\n",
    "    driver.get(url)\n",
    "    time.sleep(30)  # Wait for the page to load\n",
    "    \n",
    "    try:\n",
    "        # Locate the element using the full XPath\n",
    "        selector = \"#sysuagrfy86c > div > div > div.gridCss_g8pua0l.gridlikeCss_g26f39k > div:nth-child(2) > div > div.gridCss_g8pua0l.gridlikeCss_g26f39k > div > div > div > div.css-17qa5ny > div > div > ul > div:nth-child(1) > div > div:nth-child(2) > div > div > div:nth-child(1) > div > div > div:nth-child(2) > div > span > div > div:nth-child(4) > button\"\n",
    "        element = driver.find_element(By.CSS_SELECTOR, selector)\n",
    "        \n",
    "        # Extract the aria-label attribute and format it\n",
    "        aria_label = element.get_attribute('aria-label').replace(\" \", \"\")\n",
    "        aria_label = aria_label[:4] + '-' + aria_label[4:]\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        # If the element is not found, set aria_label to an empty string\n",
    "        aria_label = \"\"\n",
    "    \n",
    "    urls_df.loc[index, 'Father'] = str(aria_label)  # Store the aria_label\n",
    "    # Store the aria_label in the pids list\n",
    "    pids.append({'url': url, 'aria_label': aria_label})\n",
    "    print(f\"Processed {url} - aria-label: {aria_label}\")\n",
    "    try:\n",
    "        # Locate the element using the full XPath\n",
    "        selector = \"#sysuagrfy86c > div > div > div.gridCss_g8pua0l.gridlikeCss_g26f39k > div:nth-child(2) > div > div.gridCss_g8pua0l.gridlikeCss_g26f39k > div > div > div > div.css-17qa5ny > div > div > ul > div:nth-child(3) > div > div:nth-child(2) > div > div > div:nth-child(1) > div > div > div:nth-child(2) > div > span > div > div:nth-child(4) > button\"\n",
    "        element = driver.find_element(By.CSS_SELECTOR, selector)\n",
    "\n",
    "        # Extract the aria-label attribute and format it\n",
    "        aria_label = element.get_attribute('aria-label').replace(\" \", \"\")\n",
    "        aria_label = aria_label[:4] + '-' + aria_label[4:]\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        # If the element is not found, set aria_label to an empty string\n",
    "        aria_label = \"\"\n",
    "    urls_df.loc[index, 'Mother'] = str(aria_label)  # Convert to string for aria_label\n",
    "    # Store the aria_label in the pids list\n",
    "    pids.append({'url': url, 'aria_label': aria_label})\n",
    "    print(f\"Processed {url} - aria-label: {aria_label}\")\n",
    "\n",
    "\n",
    "# Save the results to a CSV file\n",
    "pd.DataFrame(urls_df).to_csv('test.csv', index=False)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import undetected_chromedriver as uc\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "# Set up undetected-chromedriver\n",
    "options = uc.ChromeOptions()\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "# Create the WebDriver instance\n",
    "driver = uc.Chrome(options=options)\n",
    "\n",
    "# Open Chrome and let the user log in manually\n",
    "print(\"Please log in to the site manually in the opened Chrome window. Press Enter when done...\")\n",
    "input(\"Press Enter to continue after logging in...\")\n",
    "\n",
    "# Load your DataFrame with URLs\n",
    "urls_df = pd.read_csv('test.csv')  # Replace 'HStoExcel.csv' with your actual CSV file\n",
    "\n",
    "# Initialize a list to store PIDs\n",
    "pids = []\n",
    "\n",
    "# Loop through URLs and capture information\n",
    "for index, row in urls_df.iterrows():\n",
    "    url = row['url']\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "    \n",
    "    # Find all buttons with data-testid=\"pid\" and extract their text\n",
    "    pid_elements = driver.find_elements(By.CSS_SELECTOR, 'button[data-testid=\"pid\"]')\n",
    "    for element in pid_elements:\n",
    "        pids.append(element.text)\n",
    "    \n",
    "    # Print or save the PIDs as needed\n",
    "    print(f\"Page {index + 1}: Found {len(pid_elements)} PIDs.\")\n",
    "\n",
    "# Optionally, save the PIDs to a CSV file\n",
    "pids_df = pd.DataFrame(pids, columns=['PID'])\n",
    "pids_df.to_csv('captured_pids.csv', index=False)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "# Optionally, save the captured data to a CSV file\n",
    "# captured_data_df.to_csv('captured_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please log in to the site manually in the opened Chrome window. Press Enter when done...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harmk\\AppData\\Local\\Temp\\ipykernel_12428\\2836572013.py:52: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'KWZN-1JQ' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  urls_df.iloc[index, urls_df.columns.get_loc('Father')] = father_pid\n",
      "C:\\Users\\harmk\\AppData\\Local\\Temp\\ipykernel_12428\\2836572013.py:54: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'KKZ4-Y8C' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  urls_df.iloc[index, urls_df.columns.get_loc('Mother')] = mother_pid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1: Found 14 PIDs.\n",
      "Page 2: Found 12 PIDs.\n",
      "Page 3: Found 17 PIDs.\n",
      "Page 4: Found 38 PIDs.\n",
      "Page 5: Found 22 PIDs.\n",
      "Page 6: Found 23 PIDs.\n",
      "Page 7: Found 25 PIDs.\n",
      "Page 8: Found 12 PIDs.\n",
      "Page 9: Found 11 PIDs.\n",
      "Page 10: Found 12 PIDs.\n",
      "Page 11: Found 13 PIDs.\n",
      "Page 12: Found 20 PIDs.\n",
      "Page 13: Found 28 PIDs.\n",
      "Page 14: Found 16 PIDs.\n",
      "Page 15: Found 14 PIDs.\n",
      "Page 16: Found 13 PIDs.\n",
      "Page 17: Found 16 PIDs.\n",
      "Page 18: Found 15 PIDs.\n",
      "Page 19: Found 16 PIDs.\n",
      "Page 20: Found 18 PIDs.\n",
      "Page 21: Found 11 PIDs.\n",
      "Page 22: Found 5 PIDs.\n",
      "Page 23: Found 11 PIDs.\n",
      "Page 24: Found 13 PIDs.\n",
      "Page 25: Found 21 PIDs.\n",
      "Page 26: Found 16 PIDs.\n",
      "Page 27: Found 9 PIDs.\n",
      "Page 28: Found 14 PIDs.\n",
      "Page 29: Found 9 PIDs.\n",
      "Page 30: Found 19 PIDs.\n",
      "Page 31: Found 9 PIDs.\n",
      "Page 32: Found 16 PIDs.\n",
      "Page 33: Found 14 PIDs.\n"
     ]
    }
   ],
   "source": [
    "import undetected_chromedriver as uc\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "# Set up undetected-chromedriver\n",
    "options = uc.ChromeOptions()\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "# Create the WebDriver instance\n",
    "driver = uc.Chrome(options=options)\n",
    "\n",
    "# Open Chrome and let the user log in manually\n",
    "print(\"Please log in to the site manually in the opened Chrome window. Press Enter when done...\")\n",
    "input(\"Press Enter to continue after logging in...\")\n",
    "\n",
    "# Load your DataFrame with URLs\n",
    "urls_df = pd.read_csv('test.csv')  # Replace 'HStoExcel.csv' with your actual CSV file\n",
    "\n",
    "# Initialize a list to store PIDs and their locations\n",
    "pids = []\n",
    "pid_locations = []\n",
    "\n",
    "# Loop through URLs and capture information\n",
    "for index, row in urls_df.iterrows():\n",
    "    url = row['url']\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "    # Find all buttons with data-testid=\"pid\" and extract their text and location\n",
    "    pid_elements = driver.find_elements(By.CSS_SELECTOR, 'button[data-testid=\"pid\"]')\n",
    "    for element in pid_elements:\n",
    "        pids.append(element.text)\n",
    "        pid_locations.append(element.location)\n",
    "\n",
    "    # Find the first and second PIDs with an 'X' location > 650 but < 700\n",
    "    father_pid = None\n",
    "    mother_pid = None\n",
    "    count = 0\n",
    "    for pid, location in zip(pids, pid_locations):\n",
    "        if 650 < location['x'] < 700:\n",
    "            if count == 0:\n",
    "                father_pid = pid\n",
    "            elif count == 1:\n",
    "                mother_pid = pid\n",
    "            count += 1\n",
    "            if count == 2:\n",
    "                break\n",
    "\n",
    "    # Store the PIDs in the DataFrame\n",
    "    if father_pid:\n",
    "        urls_df.iloc[index, urls_df.columns.get_loc('Father')] = father_pid\n",
    "    if mother_pid:\n",
    "        urls_df.iloc[index, urls_df.columns.get_loc('Mother')] = mother_pid\n",
    "\n",
    "    # Print or save the PIDs as needed\n",
    "    print(f\"Page {index + 1}: Found {len(pid_elements)} PIDs.\")\n",
    "\n",
    "    # Reset pids and pid_locations for the next iteration\n",
    "    pids = []\n",
    "    pid_locations = []\n",
    "\n",
    "# Save the updated DataFrame to a CSV file\n",
    "urls_df.to_csv('updated_urls.csv', index=False)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "# Optionally, save the captured data to a CSV file\n",
    "# captured_data_df.to_csv('captured_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_df.to_csv('updated_urls.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
