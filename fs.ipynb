{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import undetected_chromedriver as uc\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "# Set up undetected-chromedriver\n",
    "options = uc.ChromeOptions()\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "# Create the WebDriver instance\n",
    "driver = uc.Chrome(options=options)\n",
    "\n",
    "# Open Chrome and let the user log in manually\n",
    "print(\"Please log in to the site manually in the opened Chrome window. Press Enter when done...\")\n",
    "input(\"Press Enter to continue after logging in...\")\n",
    "\n",
    "# Load your DataFrame with URLs\n",
    "urls_df = pd.read_csv('test.csv')  # Replace 'HStoExcel.csv' with your actual CSV file\n",
    "\n",
    "# Initialize a list to store PIDs\n",
    "pids = []\n",
    "\n",
    "# Loop through URLs and capture information\n",
    "for index, row in urls_df.iterrows():\n",
    "    url = row['url']\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "    \n",
    "    # Find all buttons with data-testid=\"pid\" and extract their text\n",
    "    pid_elements = driver.find_elements(By.CSS_SELECTOR, 'button[data-testid=\"pid\"]')\n",
    "    for element in pid_elements:\n",
    "        pids.append(element.text)\n",
    "    \n",
    "    # Print or save the PIDs as needed\n",
    "    print(f\"Page {index + 1}: Found {len(pid_elements)} PIDs.\")\n",
    "\n",
    "# Optionally, save the PIDs to a CSV file\n",
    "pids_df = pd.DataFrame(pids, columns=['PID'])\n",
    "pids_df.to_csv('captured_pids.csv', index=False)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "# Optionally, save the captured data to a CSV file\n",
    "# captured_data_df.to_csv('captured_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import undetected_chromedriver as uc\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "\n",
    "# Set up undetected-chromedriver\n",
    "options = uc.ChromeOptions()\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "# Create the WebDriver instance\n",
    "driver = uc.Chrome(options=options)\n",
    "\n",
    "# Open Chrome and let the user log in manually\n",
    "print(\"Please log in to the site manually in the opened Chrome window. Press Enter when done...\")\n",
    "input(\"Press Enter to continue after logging in...\")\n",
    "\n",
    "# Load your DataFrame with URLs\n",
    "urls_df = pd.read_csv('test.csv')  # Replace 'test.csv' with your actual CSV file\n",
    "urls_df['Father'] = urls_df['Father'].astype(object)\n",
    "urls_df['Mother'] = urls_df['Mother'].astype(object)\n",
    "\n",
    "# Initialize a list to store PIDs or aria-labels\n",
    "pids = []\n",
    "\n",
    "# Loop through URLs and capture information\n",
    "for index, row in urls_df.iterrows():\n",
    "    url = row['url']\n",
    "    driver.get(url)\n",
    "    time.sleep(30)  # Wait for the page to load\n",
    "    \n",
    "    try:\n",
    "        # Locate the element using the full XPath\n",
    "        selector = \"#sysuagrfy86c > div > div > div.gridCss_g8pua0l.gridlikeCss_g26f39k > div:nth-child(2) > div > div.gridCss_g8pua0l.gridlikeCss_g26f39k > div > div > div > div.css-17qa5ny > div > div > ul > div:nth-child(1) > div > div:nth-child(2) > div > div > div:nth-child(1) > div > div > div:nth-child(2) > div > span > div > div:nth-child(4) > button\"\n",
    "        element = driver.find_element(By.CSS_SELECTOR, selector)\n",
    "        \n",
    "        # Extract the aria-label attribute and format it\n",
    "        aria_label = element.get_attribute('aria-label').replace(\" \", \"\")\n",
    "        aria_label = aria_label[:4] + '-' + aria_label[4:]\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        # If the element is not found, set aria_label to an empty string\n",
    "        aria_label = \"\"\n",
    "    \n",
    "    urls_df.loc[index, 'Father'] = str(aria_label)  # Store the aria_label\n",
    "    # Store the aria_label in the pids list\n",
    "    pids.append({'url': url, 'aria_label': aria_label})\n",
    "    print(f\"Processed {url} - aria-label: {aria_label}\")\n",
    "    try:\n",
    "        # Locate the element using the full XPath\n",
    "        selector = \"#sysuagrfy86c > div > div > div.gridCss_g8pua0l.gridlikeCss_g26f39k > div:nth-child(2) > div > div.gridCss_g8pua0l.gridlikeCss_g26f39k > div > div > div > div.css-17qa5ny > div > div > ul > div:nth-child(3) > div > div:nth-child(2) > div > div > div:nth-child(1) > div > div > div:nth-child(2) > div > span > div > div:nth-child(4) > button\"\n",
    "        element = driver.find_element(By.CSS_SELECTOR, selector)\n",
    "\n",
    "        # Extract the aria-label attribute and format it\n",
    "        aria_label = element.get_attribute('aria-label').replace(\" \", \"\")\n",
    "        aria_label = aria_label[:4] + '-' + aria_label[4:]\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        # If the element is not found, set aria_label to an empty string\n",
    "        aria_label = \"\"\n",
    "    urls_df.loc[index, 'Mother'] = str(aria_label)  # Convert to string for aria_label\n",
    "    # Store the aria_label in the pids list\n",
    "    pids.append({'url': url, 'aria_label': aria_label})\n",
    "    print(f\"Processed {url} - aria-label: {aria_label}\")\n",
    "\n",
    "\n",
    "# Save the results to a CSV file\n",
    "pd.DataFrame(urls_df).to_csv('test.csv', index=False)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import undetected_chromedriver as uc\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "# Set up undetected-chromedriver\n",
    "options = uc.ChromeOptions()\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "# Create the WebDriver instance\n",
    "driver = uc.Chrome(options=options)\n",
    "\n",
    "# Open Chrome and let the user log in manually\n",
    "print(\"Please log in to the site manually in the opened Chrome window. Press Enter when done...\")\n",
    "input(\"Press Enter to continue after logging in...\")\n",
    "\n",
    "# Load your DataFrame with URLs\n",
    "urls_df = pd.read_csv('test.csv')  # Replace 'HStoExcel.csv' with your actual CSV file\n",
    "\n",
    "# Initialize a list to store PIDs\n",
    "pids = []\n",
    "\n",
    "# Loop through URLs and capture information\n",
    "for index, row in urls_df.iterrows():\n",
    "    url = row['url']\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "    \n",
    "    # Find all buttons with data-testid=\"pid\" and extract their text\n",
    "    pid_elements = driver.find_elements(By.CSS_SELECTOR, 'button[data-testid=\"pid\"]')\n",
    "    for element in pid_elements:\n",
    "        pids.append(element.text)\n",
    "    \n",
    "    # Print or save the PIDs as needed\n",
    "    print(f\"Page {index + 1}: Found {len(pid_elements)} PIDs.\")\n",
    "\n",
    "# Optionally, save the PIDs to a CSV file\n",
    "pids_df = pd.DataFrame(pids, columns=['PID'])\n",
    "pids_df.to_csv('captured_pids.csv', index=False)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "# Optionally, save the captured data to a CSV file\n",
    "# captured_data_df.to_csv('captured_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please log in to the site manually in the opened Chrome window. Press Enter when done...\n",
      "{'x': 701, 'y': 1313}\n",
      "K2QM-Y9J\n",
      "{'x': 673, 'y': 1380}\n",
      "KHW2-75G\n",
      "Page 1351: Found 16 PIDs.\n",
      "{'x': 701, 'y': 1242}\n",
      "K2QM-Y9J\n",
      "{'x': 673, 'y': 1310}\n",
      "KHW2-75G\n",
      "Page 1352: Found 16 PIDs.\n",
      "{'x': 701, 'y': 1345}\n",
      "K2QM-Y9J\n",
      "{'x': 673, 'y': 1412}\n",
      "KHW2-75G\n",
      "Page 1353: Found 22 PIDs.\n",
      "{'x': 701, 'y': 1450}\n",
      "K2QM-Y9J\n",
      "{'x': 673, 'y': 1517}\n",
      "KHW2-75G\n",
      "Page 1354: Found 20 PIDs.\n",
      "{'x': 673, 'y': 1415}\n",
      "9Q2M-14F\n",
      "{'x': 673, 'y': 1482}\n",
      "9Q2M-BVZ\n",
      "Page 1355: Found 21 PIDs.\n",
      "{'x': 701, 'y': 1470}\n",
      "K2QM-Y9J\n",
      "{'x': 673, 'y': 1538}\n",
      "KHW2-75G\n",
      "Page 1356: Found 17 PIDs.\n",
      "{'x': 701, 'y': 1433}\n",
      "K2QM-Y9J\n",
      "{'x': 673, 'y': 1501}\n",
      "KHW2-75G\n",
      "Page 1357: Found 22 PIDs.\n",
      "{'x': 701, 'y': 1409}\n",
      "K2QM-Y9J\n",
      "{'x': 673, 'y': 1477}\n",
      "KHW2-75G\n",
      "Page 1358: Found 23 PIDs.\n",
      "{'x': 701, 'y': 1540}\n",
      "K2QM-Y9J\n",
      "{'x': 673, 'y': 1608}\n",
      "KHW2-75G\n",
      "Page 1359: Found 23 PIDs.\n",
      "{'x': 701, 'y': 1242}\n",
      "K2QM-Y9J\n",
      "{'x': 673, 'y': 1310}\n",
      "KHW2-75G\n",
      "Page 1360: Found 22 PIDs.\n"
     ]
    }
   ],
   "source": [
    "import undetected_chromedriver as uc\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "# Set up undetected-chromedriver\n",
    "options = uc.ChromeOptions()\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "# Create the WebDriver instance\n",
    "driver = uc.Chrome(options=options)\n",
    "\n",
    "# Open Chrome and let the user log in manually\n",
    "print(\"Please log in to the site manually in the opened Chrome window. Press Enter when done...\")\n",
    "input(\"Press Enter to continue after logging in...\")\n",
    "\n",
    "# Load your DataFrame with URLs\n",
    "urls_df = pd.read_csv('test.csv')  # Replace 'HStoExcel.csv' with your actual CSV file\n",
    "urls_df['Father'] = urls_df['Father'].astype(str)\n",
    "urls_df['Mother'] = urls_df['Mother'].astype(str)\n",
    "\n",
    "# Initialize a list to store PIDs and their locations\n",
    "pids = []\n",
    "pid_locations = []\n",
    "father_pid = None\n",
    "mother_pid = None\n",
    "pid_elements = []\n",
    "\n",
    "# Loop through URLs and capture information\n",
    "for index, row in urls_df[1360:2000].iterrows():\n",
    "    url = row['url']\n",
    "    driver.get(url)\n",
    "    time.sleep(6)  # Wait for the page to load\n",
    "\n",
    "    # Find all buttons with data-testid=\"pid\" and extract their text and location\n",
    "    pid_elements = driver.find_elements(By.CSS_SELECTOR, 'button[data-testid=\"pid\"]')\n",
    "    for element in pid_elements:\n",
    "        pids.append(element.text)\n",
    "        pid_locations.append(element.location)\n",
    "\n",
    "    # Find the first and second PIDs with an 'X' location > 650 but < 700\n",
    "    father_pid = None\n",
    "    mother_pid = None\n",
    "    count = 0\n",
    "    for pid, location in zip(pids, pid_locations):\n",
    "        if 650 < location['x'] < 800:\n",
    "            print(location)\n",
    "            if count == 0:\n",
    "                print(pid)\n",
    "                urls_df.iloc[index, urls_df.columns.get_loc('Father')] = pid\n",
    "            elif count == 1:\n",
    "                print(pid)\n",
    "                urls_df.iloc[index, urls_df.columns.get_loc('Mother')] = pid\n",
    "            count += 1\n",
    "            if count == 2:\n",
    "                break\n",
    "\n",
    "    # Print or save the PIDs as needed\n",
    "    print(f\"Page {index + 1}: Found {len(pid_elements)} PIDs.\")\n",
    "\n",
    "    # Reset pids and pid_locations for the next iteration\n",
    "    pids = []\n",
    "    pid_locations = []\n",
    "\n",
    "# Save the updated DataFrame to a CSV file\n",
    "urls_df.to_csv('test.csv', index=False)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "# Optionally, save the captured data to a CSV file\n",
    "# captured_data_df.to_csv('captured_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_df.to_csv('test.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
